{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from agent.graph_extractor import GraphExtractor\n",
    "from environment.environment import Environment\n",
    "from smu_grid import Grid\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_checker import check_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumRatioConfig(consumer=0.3, generator=0.4, renewable=0.2, sink=0.1)\n",
      "Initialization: Found steady state after 1 trials\n",
      "Initialization: perturbation will be [0 0 1 0 0 0 0 0 0 0]\n",
      "NumRatioConfig(consumer=0.3, generator=0.4, renewable=0.2, sink=0.1)\n",
      "Reset: Found steady state after 1 trials\n",
      "Reset: perturbation will be [0 0 0 0 0 0 0 0 0 1]\n",
      "Step: after pre-processing, action=[0.9  0.   0.   0.   0.12 0.97 0.85 0.   0.92 0.  ]\n",
      "Step: successfully finished rebalancing, reward=-1.26e-04\n",
      "Step: next perturbation will be [0 0 0 0 0 0 0 0 0 1]\n",
      "Step: after pre-processing, action=[0.4  0.   0.   0.   0.84 0.17 0.34 0.   0.65 0.  ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pds/pds11/hoyun/miniconda3/envs/rl/lib/python3.10/site-packages/stable_baselines3/common/env_checker.py:237: UserWarning: Your observation edge_list has an unconventional shape (neither an image, nor a 1D vector). We recommend you to flatten the observation to have only a 1D vector or use a custom policy to properly process the data.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: successfully finished rebalancing, reward=-1.96e-04\n",
      "Step: next perturbation will be [0 1 0 0 0 0 0 0 0 0]\n",
      "Step: after pre-processing, action=[0.51 0.   0.   0.   0.37 0.61 0.07 0.   0.67 0.  ]\n",
      "Step: successfully finished rebalancing, reward=-2.84e-04\n",
      "Step: next perturbation will be [0 0 0 1 0 0 0 0 0 0]\n",
      "Step: after pre-processing, action=[0.83 0.   0.   0.   0.72 0.32 0.08 0.   0.64 0.  ]\n",
      "Step: successfully finished rebalancing, reward=-4.22e-04\n",
      "Step: next perturbation will be [0 0 0 1 0 0 0 0 0 0]\n",
      "Step: after pre-processing, action=[0.32 0.   0.   0.   0.4  0.03 0.42 0.   0.65 0.  ]\n",
      "Step: successfully finished rebalancing, reward=-5.38e-04\n",
      "Step: next perturbation will be [0 0 1 0 0 0 0 0 0 0]\n",
      "Step: after pre-processing, action=[0.17 0.   0.   0.   0.77 0.95 0.28 0.   0.68 0.  ]\n",
      "Step: successfully finished rebalancing, reward=-2.05e-04\n",
      "Step: next perturbation will be [0 1 0 0 0 0 0 0 0 0]\n",
      "Step: after pre-processing, action=[0.51 0.   0.   0.   0.32 0.59 0.03 0.   0.49 0.  ]\n",
      "Step: successfully finished rebalancing, reward=-1.40e-04\n",
      "Step: next perturbation will be [0 0 1 0 0 0 0 0 0 0]\n",
      "Step: after pre-processing, action=[0.07 0.   0.   0.   0.17 0.33 0.81 0.   0.03 0.  ]\n",
      "Step: successfully finished rebalancing, reward=-8.98e-04\n",
      "Step: next perturbation will be [0 1 0 0 0 0 0 0 0 0]\n",
      "Step: after pre-processing, action=[0.54 0.   0.   0.   0.76 0.83 0.11 0.   0.17 0.  ]\n",
      "Step: successfully finished rebalancing, reward=-1.39e-04\n",
      "Step: next perturbation will be [0 0 0 0 0 0 0 0 0 1]\n",
      "Step: after pre-processing, action=[0.91 0.   0.   0.   0.02 0.95 0.75 0.   0.06 0.  ]\n",
      "Step: No steady state after rebalancing. reward=-5.00e+01\n",
      "Step: next perturbation will be [0 1 0 0 0 0 0 0 0 0]\n",
      "NumRatioConfig(consumer=0.3, generator=0.4, renewable=0.2, sink=0.1)\n",
      "Reset: Found steady state after 1 trials\n",
      "Reset: perturbation will be [0 0 0 0 0 0 0 1 0 0]\n",
      "Step: after pre-processing, action=[0.76 0.44 0.   0.93 0.16 0.09 0.   0.   0.   0.  ]\n",
      "Step: No steady state after rebalancing. reward=-5.00e+01\n",
      "Step: next perturbation will be [0 0 0 0 0 0 0 0 1 0]\n",
      "NumRatioConfig(consumer=0.3, generator=0.4, renewable=0.2, sink=0.1)\n",
      "Reset: Found steady state after 1 trials\n",
      "Reset: perturbation will be [ 0  0  0  0  0  0 -1  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "rng = np.random.default_rng(0)\n",
    "grid = Grid(rng=rng)\n",
    "grid.turn_on()\n",
    "\n",
    "env = Environment(grid, rng, verbose=2)\n",
    "check_env(env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0 device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "policy_kwargs = {\"features_extractor_class\": GraphExtractor}\n",
    "model = PPO(\n",
    "    \"MultiInputPolicy\",\n",
    "    env,\n",
    "    policy_kwargs=policy_kwargs,\n",
    "    verbose=2,\n",
    "    device=device,\n",
    "    n_steps=128,\n",
    ")\n",
    "\n",
    "# feature_extractor = cast(GraphExtractor, model.policy.features_extractor)\n",
    "# obs = {\n",
    "#     key: torch.tensor(value, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "#     for key, value in env.observe().items()\n",
    "# }\n",
    "# print(summary(feature_extractor, obs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumRatioConfig(consumer=0.3, generator=0.4, renewable=0.2, sink=0.1)\n",
      "Reset: Found steady state after 1 trials\n",
      "Reset: perturbation will be [0 0 1 0 0 0 0 0 0 0]\n",
      "tensor([[2., 0., 1., 0., 3., 2., 2., 0., 1., 0.]], device='cuda:0') torch.float32\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mlearn(total_timesteps\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m \u001b[39m*\u001b[39;49m \u001b[39m10\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/rl/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py:304\u001b[0m, in \u001b[0;36mPPO.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlearn\u001b[39m(\n\u001b[1;32m    296\u001b[0m     \u001b[39mself\u001b[39m: SelfPPO,\n\u001b[1;32m    297\u001b[0m     total_timesteps: \u001b[39mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    302\u001b[0m     progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    303\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m SelfPPO:\n\u001b[0;32m--> 304\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mlearn(\n\u001b[1;32m    305\u001b[0m         total_timesteps\u001b[39m=\u001b[39;49mtotal_timesteps,\n\u001b[1;32m    306\u001b[0m         callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[1;32m    307\u001b[0m         log_interval\u001b[39m=\u001b[39;49mlog_interval,\n\u001b[1;32m    308\u001b[0m         tb_log_name\u001b[39m=\u001b[39;49mtb_log_name,\n\u001b[1;32m    309\u001b[0m         reset_num_timesteps\u001b[39m=\u001b[39;49mreset_num_timesteps,\n\u001b[1;32m    310\u001b[0m         progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m    311\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/rl/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py:246\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    243\u001b[0m callback\u001b[39m.\u001b[39mon_training_start(\u001b[39mlocals\u001b[39m(), \u001b[39mglobals\u001b[39m())\n\u001b[1;32m    245\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_timesteps \u001b[39m<\u001b[39m total_timesteps:\n\u001b[0;32m--> 246\u001b[0m     continue_training \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollect_rollouts(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv, callback, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrollout_buffer, n_rollout_steps\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_steps)\n\u001b[1;32m    248\u001b[0m     \u001b[39mif\u001b[39;00m continue_training \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m    249\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/rl/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py:165\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.collect_rollouts\u001b[0;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[39mwith\u001b[39;00m th\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m    163\u001b[0m     \u001b[39m# Convert to pytorch tensor or to TensorDict\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     obs_tensor \u001b[39m=\u001b[39m obs_as_tensor(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_last_obs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m--> 165\u001b[0m     actions, values, log_probs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpolicy(obs_tensor)\n\u001b[1;32m    166\u001b[0m actions \u001b[39m=\u001b[39m actions\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m    168\u001b[0m \u001b[39m# Rescale and perform action\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/rl/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/rl/lib/python3.10/site-packages/stable_baselines3/common/policies.py:599\u001b[0m, in \u001b[0;36mActorCriticPolicy.forward\u001b[0;34m(self, obs, deterministic)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    592\u001b[0m \u001b[39mForward pass in all the networks (actor and critic)\u001b[39;00m\n\u001b[1;32m    593\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[39m:return: action, value and log probability of the action\u001b[39;00m\n\u001b[1;32m    597\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    598\u001b[0m \u001b[39m# Preprocess the observation if needed\u001b[39;00m\n\u001b[0;32m--> 599\u001b[0m features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mextract_features(obs)\n\u001b[1;32m    600\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshare_features_extractor:\n\u001b[1;32m    601\u001b[0m     latent_pi, latent_vf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmlp_extractor(features)\n",
      "File \u001b[0;32m~/miniconda3/envs/rl/lib/python3.10/site-packages/stable_baselines3/common/policies.py:622\u001b[0m, in \u001b[0;36mActorCriticPolicy.extract_features\u001b[0;34m(self, obs)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    616\u001b[0m \u001b[39mPreprocess the observation if needed and extract features.\u001b[39;00m\n\u001b[1;32m    617\u001b[0m \n\u001b[1;32m    618\u001b[0m \u001b[39m:param obs: Observation\u001b[39;00m\n\u001b[1;32m    619\u001b[0m \u001b[39m:return: the output of the features extractor(s)\u001b[39;00m\n\u001b[1;32m    620\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    621\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshare_features_extractor:\n\u001b[0;32m--> 622\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mextract_features(obs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeatures_extractor)\n\u001b[1;32m    623\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    624\u001b[0m     pi_features \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mextract_features(obs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpi_features_extractor)\n",
      "File \u001b[0;32m~/miniconda3/envs/rl/lib/python3.10/site-packages/stable_baselines3/common/policies.py:130\u001b[0m, in \u001b[0;36mBaseModel.extract_features\u001b[0;34m(self, obs, features_extractor)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[39mPreprocess the observation if needed and extract features.\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m :return: The extracted features\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    129\u001b[0m preprocessed_obs \u001b[39m=\u001b[39m preprocess_obs(obs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobservation_space, normalize_images\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnormalize_images)\n\u001b[0;32m--> 130\u001b[0m \u001b[39mreturn\u001b[39;00m features_extractor(preprocessed_obs)\n",
      "File \u001b[0;32m~/miniconda3/envs/rl/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/swing_rl/SMU_v2/agent/graph_extractor.py:211\u001b[0m, in \u001b[0;36mGraphExtractor.forward\u001b[0;34m(self, observations)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    208\u001b[0m     \u001b[39mself\u001b[39m, observations: OrderedDict[OBSERVATION, torch\u001b[39m.\u001b[39mTensor]\n\u001b[1;32m    209\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m    210\u001b[0m     \u001b[39mprint\u001b[39m(observations[\u001b[39m\"\u001b[39m\u001b[39mnode_type\u001b[39m\u001b[39m\"\u001b[39m], observations[\u001b[39m\"\u001b[39m\u001b[39mnode_type\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mdtype)\n\u001b[0;32m--> 211\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     edge_index \u001b[39m=\u001b[39m observations[\u001b[39m\"\u001b[39m\u001b[39medge_list\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mto(dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mint64)  \u001b[39m# [B, 2, E]\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     num_batch \u001b[39m=\u001b[39m edge_index\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.learn(total_timesteps=128 * 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
